{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nComparison of Dimension Reduction Techniques\n--------------------------------------------\n\nA comparison of several different dimension reduction\ntechniques on a variety of toy datasets. The datasets\nare all toy datasets, but should provide a representative\nrange of the strengths and weaknesses of the different\nalgorithms.\n\nThe time to perform the dimension reduction with each\nalgorithm and each dataset is recorded in the lower\nright of each plot.\n\nThings to note about the datasets:\n\n- Blobs: A set of five gaussian blobs in 10 dimensional\n         space. This should be a prototypical example\n         of something that should clearly separate\n         even in a reduced dimension space.\n- Iris: a classic small dataset with one distinct class\n        and two classes that are not clearly separated.\n- Digits: handwritten digits -- ideally different digit\n          classes should form distinct groups. Due to\n          the nature of handwriting digits may have several\n          forms (crossed or uncrossed sevens, capped or\n          straight line oes, etc.)\n- Wine: wine characteristics ideally used for a toy\n        regression. Ultimately the data is essentially\n        one dimensional in nature.\n- Swiss Roll: data is essentially a rectangle, but\n              has been \"rolled up\" like a swiss roll\n              in three dimensional space. Ideally a\n              dimension reduction technique should\n              be able to \"unroll\" it. The data\n              has been coloured according to one dimension\n              of the rectangle, so should form\n              a rectangle of smooth color variation.\n- Sphere: the two dimensional surface of a three\n          dimensional sphere. This cannot be represented\n          accurately in two dimensions without tearing.\n          The sphere has been coloured with hue around\n          the equator and black to white from the south\n          to north pole.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\n\nfrom sklearn import datasets, decomposition, manifold, preprocessing\nfrom colorsys import hsv_to_rgb\n\nimport umap\n\nsns.set(context=\"paper\", style=\"white\")\n\nblobs, blob_labels = datasets.make_blobs(\n    n_samples=500, n_features=10, centers=5, random_state=42\n)\niris = datasets.load_iris()\ndigits = datasets.load_digits(n_class=10)\nwine = datasets.load_wine()\nswissroll, swissroll_labels = datasets.make_swiss_roll(\n    n_samples=1000, noise=0.1, random_state=42\n)\nsphere = np.random.normal(size=(600, 3))\nsphere = preprocessing.normalize(sphere)\nsphere_hsv = np.array(\n    [\n        (\n            (np.arctan2(c[1], c[0]) + np.pi) / (2 * np.pi),\n            np.abs(c[2]),\n            min((c[2] + 1.1), 1.0),\n        )\n        for c in sphere\n    ]\n)\nsphere_colors = np.array([hsv_to_rgb(*c) for c in sphere_hsv])\n\nreducers = [\n    (manifold.TSNE, {\"perplexity\": 50}),\n    # (manifold.LocallyLinearEmbedding, {'n_neighbors':10, 'method':'hessian'}),\n    (manifold.Isomap, {\"n_neighbors\": 30}),\n    (manifold.MDS, {}),\n    (decomposition.PCA, {}),\n    (umap.UMAP, {\"n_neighbors\": 30, \"min_dist\": 0.3}),\n]\n\ntest_data = [\n    (blobs, blob_labels),\n    (iris.data, iris.target),\n    (digits.data, digits.target),\n    (wine.data, wine.target),\n    (swissroll, swissroll_labels),\n    (sphere, sphere_colors),\n]\ndataset_names = [\"Blobs\", \"Iris\", \"Digits\", \"Wine\", \"Swiss Roll\", \"Sphere\"]\n\nn_rows = len(test_data)\nn_cols = len(reducers)\nax_index = 1\nax_list = []\n\n# plt.figure(figsize=(9 * 2 + 3, 12.5))\nplt.figure(figsize=(10, 8))\nplt.subplots_adjust(\n    left=.02, right=.98, bottom=.001, top=.96, wspace=.05, hspace=.01\n)\nfor data, labels in test_data:\n    for reducer, args in reducers:\n        start_time = time.time()\n        embedding = reducer(n_components=2, **args).fit_transform(data)\n        elapsed_time = time.time() - start_time\n        ax = plt.subplot(n_rows, n_cols, ax_index)\n        if isinstance(labels[0], tuple):\n            ax.scatter(*embedding.T, s=10, c=labels, alpha=0.5)\n        else:\n            ax.scatter(\n                *embedding.T, s=10, c=labels, cmap=\"Spectral\", alpha=0.5\n            )\n        ax.text(\n            0.99,\n            0.01,\n            \"{:.2f} s\".format(elapsed_time),\n            transform=ax.transAxes,\n            size=14,\n            horizontalalignment=\"right\",\n        )\n        ax_list.append(ax)\n        ax_index += 1\nplt.setp(ax_list, xticks=[], yticks=[])\n\nfor i in np.arange(n_rows) * n_cols:\n    ax_list[i].set_ylabel(dataset_names[i // n_cols], size=16)\nfor i in range(n_cols):\n    ax_list[i].set_xlabel(repr(reducers[i][0]()).split(\"(\")[0], size=16)\n    ax_list[i].xaxis.set_label_position(\"top\")\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}